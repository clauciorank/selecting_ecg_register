{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "torch.cuda.manual_seed(42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reading files and selecting columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('df_for_modeling.csv')\n",
    "\n",
    "X_df = dataset.drop(['file_name', 'selected'], axis = 1)\n",
    "y_df = dataset['selected']\n",
    "files = dataset['file_name']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_df, X_test_df, y_train_df, y_test_df = train_test_split(\n",
    "    X_df,\n",
    "    y_df,\n",
    "    test_size=.3,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforming to torch and using gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make device agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device\n",
    "\n",
    "X_train = torch.from_numpy(X_train_df.to_numpy()).to(device).type(torch.float)\n",
    "X_test = torch.from_numpy(X_test_df.to_numpy()).to(device).type(torch.float)\n",
    "y_train = torch.from_numpy(y_train_df.to_numpy()).to(device).type(torch.float)\n",
    "y_test = torch.from_numpy(y_test_df.to_numpy()).to(device).type(torch.float)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class model(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        # layers\n",
    "        self.layer1 = nn.Linear(in_features=input_dim, out_features=hidden_dim)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.layer2 = nn.Linear(in_features=hidden_dim, out_features=100)\n",
    "        self.layer3 = nn.Linear(in_features=100, out_features=output_dim)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        #Forward\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.activation(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.activation(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.sigmoid(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/10000], Loss: 0.6079\n",
      "Accuracy: 71.84%\n",
      "Epoch [200/10000], Loss: 0.5984\n",
      "Accuracy: 71.84%\n",
      "Epoch [300/10000], Loss: 0.5951\n",
      "Accuracy: 71.84%\n",
      "Epoch [400/10000], Loss: 0.5920\n",
      "Accuracy: 71.84%\n",
      "Epoch [500/10000], Loss: 0.5885\n",
      "Accuracy: 71.84%\n",
      "Epoch [600/10000], Loss: 0.5847\n",
      "Accuracy: 71.84%\n",
      "Epoch [700/10000], Loss: 0.5803\n",
      "Accuracy: 71.84%\n",
      "Epoch [800/10000], Loss: 0.5754\n",
      "Accuracy: 71.84%\n",
      "Epoch [900/10000], Loss: 0.5697\n",
      "Accuracy: 71.87%\n",
      "Epoch [1000/10000], Loss: 0.5633\n",
      "Accuracy: 71.94%\n",
      "Epoch [1100/10000], Loss: 0.5562\n",
      "Accuracy: 72.08%\n",
      "Epoch [1200/10000], Loss: 0.5485\n",
      "Accuracy: 72.53%\n",
      "Epoch [1300/10000], Loss: 0.5405\n",
      "Accuracy: 72.88%\n",
      "Epoch [1400/10000], Loss: 0.5327\n",
      "Accuracy: 73.68%\n",
      "Epoch [1500/10000], Loss: 0.5252\n",
      "Accuracy: 74.14%\n",
      "Epoch [1600/10000], Loss: 0.5184\n",
      "Accuracy: 74.76%\n",
      "Epoch [1700/10000], Loss: 0.5124\n",
      "Accuracy: 75.11%\n",
      "Epoch [1800/10000], Loss: 0.5072\n",
      "Accuracy: 75.95%\n",
      "Epoch [1900/10000], Loss: 0.5027\n",
      "Accuracy: 76.37%\n",
      "Epoch [2000/10000], Loss: 0.4990\n",
      "Accuracy: 76.58%\n",
      "Epoch [2100/10000], Loss: 0.4959\n",
      "Accuracy: 76.61%\n",
      "Epoch [2200/10000], Loss: 0.4932\n",
      "Accuracy: 76.93%\n",
      "Epoch [2300/10000], Loss: 0.4909\n",
      "Accuracy: 77.07%\n",
      "Epoch [2400/10000], Loss: 0.4889\n",
      "Accuracy: 77.31%\n",
      "Epoch [2500/10000], Loss: 0.4871\n",
      "Accuracy: 77.20%\n",
      "Epoch [2600/10000], Loss: 0.4855\n",
      "Accuracy: 77.45%\n",
      "Epoch [2700/10000], Loss: 0.4841\n",
      "Accuracy: 77.45%\n",
      "Epoch [2800/10000], Loss: 0.4828\n",
      "Accuracy: 77.48%\n",
      "Epoch [2900/10000], Loss: 0.4816\n",
      "Accuracy: 77.73%\n",
      "Epoch [3000/10000], Loss: 0.4805\n",
      "Accuracy: 77.76%\n",
      "Epoch [3100/10000], Loss: 0.4794\n",
      "Accuracy: 77.69%\n",
      "Epoch [3200/10000], Loss: 0.4785\n",
      "Accuracy: 77.87%\n",
      "Epoch [3300/10000], Loss: 0.4775\n",
      "Accuracy: 77.87%\n",
      "Epoch [3400/10000], Loss: 0.4766\n",
      "Accuracy: 77.83%\n",
      "Epoch [3500/10000], Loss: 0.4758\n",
      "Accuracy: 77.87%\n",
      "Epoch [3600/10000], Loss: 0.4750\n",
      "Accuracy: 77.73%\n",
      "Epoch [3700/10000], Loss: 0.4742\n",
      "Accuracy: 77.69%\n",
      "Epoch [3800/10000], Loss: 0.4735\n",
      "Accuracy: 77.80%\n",
      "Epoch [3900/10000], Loss: 0.4728\n",
      "Accuracy: 77.97%\n",
      "Epoch [4000/10000], Loss: 0.4721\n",
      "Accuracy: 78.01%\n",
      "Epoch [4100/10000], Loss: 0.4715\n",
      "Accuracy: 78.11%\n",
      "Epoch [4200/10000], Loss: 0.4709\n",
      "Accuracy: 78.15%\n",
      "Epoch [4300/10000], Loss: 0.4703\n",
      "Accuracy: 78.04%\n",
      "Epoch [4400/10000], Loss: 0.4697\n",
      "Accuracy: 78.04%\n",
      "Epoch [4500/10000], Loss: 0.4691\n",
      "Accuracy: 78.01%\n",
      "Epoch [4600/10000], Loss: 0.4685\n",
      "Accuracy: 78.01%\n",
      "Epoch [4700/10000], Loss: 0.4679\n",
      "Accuracy: 77.97%\n",
      "Epoch [4800/10000], Loss: 0.4674\n",
      "Accuracy: 77.90%\n",
      "Epoch [4900/10000], Loss: 0.4669\n",
      "Accuracy: 77.90%\n",
      "Epoch [5000/10000], Loss: 0.4664\n",
      "Accuracy: 77.90%\n",
      "Epoch [5100/10000], Loss: 0.4659\n",
      "Accuracy: 77.90%\n",
      "Epoch [5200/10000], Loss: 0.4654\n",
      "Accuracy: 77.94%\n",
      "Epoch [5300/10000], Loss: 0.4649\n",
      "Accuracy: 78.22%\n",
      "Epoch [5400/10000], Loss: 0.4644\n",
      "Accuracy: 78.18%\n",
      "Epoch [5500/10000], Loss: 0.4639\n",
      "Accuracy: 78.25%\n",
      "Epoch [5600/10000], Loss: 0.4635\n",
      "Accuracy: 78.25%\n",
      "Epoch [5700/10000], Loss: 0.4630\n",
      "Accuracy: 78.25%\n",
      "Epoch [5800/10000], Loss: 0.4626\n",
      "Accuracy: 78.25%\n",
      "Epoch [5900/10000], Loss: 0.4621\n",
      "Accuracy: 78.25%\n",
      "Epoch [6000/10000], Loss: 0.4617\n",
      "Accuracy: 78.25%\n",
      "Epoch [6100/10000], Loss: 0.4612\n",
      "Accuracy: 78.25%\n",
      "Epoch [6200/10000], Loss: 0.4608\n",
      "Accuracy: 78.39%\n",
      "Epoch [6300/10000], Loss: 0.4603\n",
      "Accuracy: 78.35%\n",
      "Epoch [6400/10000], Loss: 0.4599\n",
      "Accuracy: 78.46%\n",
      "Epoch [6500/10000], Loss: 0.4594\n",
      "Accuracy: 78.53%\n",
      "Epoch [6600/10000], Loss: 0.4590\n",
      "Accuracy: 78.56%\n",
      "Epoch [6700/10000], Loss: 0.4585\n",
      "Accuracy: 78.63%\n",
      "Epoch [6800/10000], Loss: 0.4581\n",
      "Accuracy: 78.63%\n",
      "Epoch [6900/10000], Loss: 0.4577\n",
      "Accuracy: 78.67%\n",
      "Epoch [7000/10000], Loss: 0.4572\n",
      "Accuracy: 78.67%\n",
      "Epoch [7100/10000], Loss: 0.4568\n",
      "Accuracy: 78.56%\n",
      "Epoch [7200/10000], Loss: 0.4563\n",
      "Accuracy: 78.67%\n",
      "Epoch [7300/10000], Loss: 0.4559\n",
      "Accuracy: 78.67%\n",
      "Epoch [7400/10000], Loss: 0.4554\n",
      "Accuracy: 78.67%\n",
      "Epoch [7500/10000], Loss: 0.4550\n",
      "Accuracy: 78.63%\n",
      "Epoch [7600/10000], Loss: 0.4546\n",
      "Accuracy: 78.81%\n",
      "Epoch [7700/10000], Loss: 0.4541\n",
      "Accuracy: 78.74%\n",
      "Epoch [7800/10000], Loss: 0.4537\n",
      "Accuracy: 78.70%\n",
      "Epoch [7900/10000], Loss: 0.4532\n",
      "Accuracy: 78.63%\n",
      "Epoch [8000/10000], Loss: 0.4527\n",
      "Accuracy: 78.63%\n",
      "Epoch [8100/10000], Loss: 0.4523\n",
      "Accuracy: 78.60%\n",
      "Epoch [8200/10000], Loss: 0.4518\n",
      "Accuracy: 78.63%\n",
      "Epoch [8300/10000], Loss: 0.4514\n",
      "Accuracy: 78.77%\n",
      "Epoch [8400/10000], Loss: 0.4509\n",
      "Accuracy: 78.77%\n",
      "Epoch [8500/10000], Loss: 0.4504\n",
      "Accuracy: 78.77%\n",
      "Epoch [8600/10000], Loss: 0.4500\n",
      "Accuracy: 78.84%\n",
      "Epoch [8700/10000], Loss: 0.4495\n",
      "Accuracy: 78.88%\n",
      "Epoch [8800/10000], Loss: 0.4490\n",
      "Accuracy: 78.84%\n",
      "Epoch [8900/10000], Loss: 0.4485\n",
      "Accuracy: 78.88%\n",
      "Epoch [9000/10000], Loss: 0.4481\n",
      "Accuracy: 78.88%\n",
      "Epoch [9100/10000], Loss: 0.4476\n",
      "Accuracy: 78.88%\n",
      "Epoch [9200/10000], Loss: 0.4471\n",
      "Accuracy: 78.84%\n",
      "Epoch [9300/10000], Loss: 0.4465\n",
      "Accuracy: 78.74%\n",
      "Epoch [9400/10000], Loss: 0.4460\n",
      "Accuracy: 78.81%\n",
      "Epoch [9500/10000], Loss: 0.4455\n",
      "Accuracy: 78.84%\n",
      "Epoch [9600/10000], Loss: 0.4449\n",
      "Accuracy: 78.91%\n",
      "Epoch [9700/10000], Loss: 0.4444\n",
      "Accuracy: 78.95%\n",
      "Epoch [9800/10000], Loss: 0.4438\n",
      "Accuracy: 79.02%\n",
      "Epoch [9900/10000], Loss: 0.4433\n",
      "Accuracy: 79.09%\n",
      "Epoch [10000/10000], Loss: 0.4427\n",
      "Accuracy: 79.09%\n"
     ]
    }
   ],
   "source": [
    "from torch import optim\n",
    "\n",
    "learning_rate = 0.01\n",
    "input_dim = 99\n",
    "output_dim = 1\n",
    "hidden_dim = 200\n",
    "epochs = 10000\n",
    "\n",
    "model0 = model(input_dim, hidden_dim, output_dim).to(device)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(model0.parameters(), lr=learning_rate)\n",
    "\n",
    "# Calculate accuracy (a classification metric)\n",
    "def accuracy_fn(y_true, y_pred):\n",
    "    correct = torch.eq(y_true, y_pred).sum().item() # torch.eq() calculates where two tensors are equal\n",
    "    acc = (correct / len(y_pred)) * 100 \n",
    "    return acc\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Forward pass\n",
    "    outputs = model0(X_train)\n",
    "\n",
    "    loss = criterion(outputs.squeeze(), y_train)\n",
    "\n",
    "    # Backward and optimize\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, epochs, loss.item()))\n",
    "\n",
    "        # Evaluate the model\n",
    "        with torch.no_grad():\n",
    "            y_pred = model0(X_test)\n",
    "            y_pred_cls = (y_pred > 0.5).float().squeeze()\n",
    "            accuracy = accuracy_fn(y_pred_cls, y_test)\n",
    "            print('Accuracy: {:.2f}%'.format(accuracy))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
